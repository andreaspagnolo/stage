{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06e2ce5d-1733-42e1-a95e-0a4cd33f0ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[7m\u001b[1mresult with threshold of 20.0%\u001b[0m\n",
      "\n",
      "Clusters with threshold 20.0%: [0, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "Clusters with Euclidean distance : [0 1 1 0 0 0]\n",
      "Clusters with K-means : [0 1 1 0 0 0]\n",
      "\n",
      "Metrics calculated on the labels obtained from the Euclidean distance:\n",
      "Silhouette Score: 0.5769178547288546\n",
      "Complementary Entropy Score: 0.08170416594551055\n",
      "Calinski-Harabasz Score: 9.13389182422757\n",
      "Reciprocal Davies-Bouldin Score: 2.3044230374050096\n",
      "Dunn index Score: 1.3556818419437022\n",
      "Gap Statistic Score: -0.5772151094638848\n",
      "\n",
      "\n",
      "To compare the results obtained with the Euclidean distance and those obtained with k-means I use the range adjusted Rand index\n",
      "range adjusted Rand index: [-1, 1]\n",
      "Threshold: 20.0%, adjusted Rand index: 1.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<caption>Table with Euclidean distance clustering values:</caption><table style=\"width:100%;\" text-align:center;\" class=\"dataframe table table-striped\">\n",
       "  <th style=\"text-align:center;\"ead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"text-align:center;\">cluster</th>\n",
       "      <th style=\"text-align:center;\">cluster elements</th>\n",
       "      <th style=\"text-align:center;\">%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">1st cluster</td>\n",
       "      <td style=\"text-align:center;\">4 patients out of 169</td>\n",
       "      <td style=\"text-align:center;\">2.366864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">2nd cluster</td>\n",
       "      <td style=\"text-align:center;\">2 patients out of 169</td>\n",
       "      <td style=\"text-align:center;\">1.183432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">no cluster</td>\n",
       "      <td style=\"text-align:center;\">163 patients out of 169</td>\n",
       "      <td style=\"text-align:center;\">96.449704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.55% of the elements were correctly classified into the two clusters. The remaining 96.45% of items were not classified\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<caption>Table with K-means clustering values:</caption><table style=\"width:100%;\" text-align:center;\" class=\"dataframe table table-striped\">\n",
       "  <th style=\"text-align:center;\"ead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"text-align:center;\">cluster</th>\n",
       "      <th style=\"text-align:center;\">cluster elements</th>\n",
       "      <th style=\"text-align:center;\">%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">1st cluster</td>\n",
       "      <td style=\"text-align:center;\">4 patients out of 169</td>\n",
       "      <td style=\"text-align:center;\">2.366864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">2nd cluster</td>\n",
       "      <td style=\"text-align:center;\">2 patients out of 169</td>\n",
       "      <td style=\"text-align:center;\">1.183432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">no cluster</td>\n",
       "      <td style=\"text-align:center;\">163 patients out of 169</td>\n",
       "      <td style=\"text-align:center;\">96.449704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[7m\u001b[1mresult with threshold of 33.0%\u001b[0m\n",
      "\n",
      "Clusters with threshold 33.0%: [0, 0, 1, -1, -1, 0, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, 0, -1, 1, -1, 0, 0, 1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1, 0, 0, -1, -1]\n",
      "Clusters with Euclidean distance : [0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "Clusters with K-means : [0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "\n",
      "Metrics calculated on the labels obtained from the Euclidean distance:\n",
      "Silhouette Score: 0.47352523759241616\n",
      "Complementary Entropy Score: 0.41867850123629713\n",
      "Calinski-Harabasz Score: 20.16776110413143\n",
      "Reciprocal Davies-Bouldin Score: 1.2639719821991038\n",
      "Dunn index Score: 1.1379421037343507\n",
      "Gap Statistic Score: -0.33486983128250136\n",
      "\n",
      "\n",
      "To compare the results obtained with the Euclidean distance and those obtained with k-means I use the range adjusted Rand index\n",
      "range adjusted Rand index: [-1, 1]\n",
      "Threshold: 33.0%, adjusted Rand index: 1.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<caption>Table with Euclidean distance clustering values:</caption><table style=\"width:100%;\" text-align:center;\" class=\"dataframe table table-striped\">\n",
       "  <th style=\"text-align:center;\"ead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"text-align:center;\">cluster</th>\n",
       "      <th style=\"text-align:center;\">cluster elements</th>\n",
       "      <th style=\"text-align:center;\">%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">1st cluster</td>\n",
       "      <td style=\"text-align:center;\">31 patients out of 169</td>\n",
       "      <td style=\"text-align:center;\">18.343195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">2nd cluster</td>\n",
       "      <td style=\"text-align:center;\">5 patients out of 169</td>\n",
       "      <td style=\"text-align:center;\">2.958580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">no cluster</td>\n",
       "      <td style=\"text-align:center;\">133 patients out of 169</td>\n",
       "      <td style=\"text-align:center;\">78.698225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.302% of the elements were correctly classified into the two clusters. The remaining 78.698% of items were not classified\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<caption>Table with K-means clustering values:</caption><table style=\"width:100%;\" text-align:center;\" class=\"dataframe table table-striped\">\n",
       "  <th style=\"text-align:center;\"ead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"text-align:center;\">cluster</th>\n",
       "      <th style=\"text-align:center;\">cluster elements</th>\n",
       "      <th style=\"text-align:center;\">%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">1st cluster</td>\n",
       "      <td style=\"text-align:center;\">31 patients out of 169</td>\n",
       "      <td style=\"text-align:center;\">18.343195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">2nd cluster</td>\n",
       "      <td style=\"text-align:center;\">5 patients out of 169</td>\n",
       "      <td style=\"text-align:center;\">2.958580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">no cluster</td>\n",
       "      <td style=\"text-align:center;\">133 patients out of 169</td>\n",
       "      <td style=\"text-align:center;\">78.698225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<caption>Table with metric result:</caption><table style=\"width:100%;\" text-align:center;\" class=\"dataframe table table-striped\">\n",
       "  <th style=\"text-align:center;\"ead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"text-align:center;\">metric</th>\n",
       "      <th style=\"text-align:center;\">result</th>\n",
       "      <th style=\"text-align:center;\">time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">Silhouette</td>\n",
       "      <td style=\"text-align:center;\">Correct</td>\n",
       "      <td style=\"text-align:center;\">2.914 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">Complementary Entropy</td>\n",
       "      <td style=\"text-align:center;\">Wrong</td>\n",
       "      <td style=\"text-align:center;\">0.701 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">Reciprocal Davies-Bouldin</td>\n",
       "      <td style=\"text-align:center;\">Correct</td>\n",
       "      <td style=\"text-align:center;\">2.83 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">Dunn index</td>\n",
       "      <td style=\"text-align:center;\">Correct</td>\n",
       "      <td style=\"text-align:center;\">2.624 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">Calinski-Harabasz</td>\n",
       "      <td style=\"text-align:center;\">Wrong</td>\n",
       "      <td style=\"text-align:center;\">1.997 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style=\"text-align:center;\">Gap Statistic</td>\n",
       "      <td style=\"text-align:center;\">Correct</td>\n",
       "      <td style=\"text-align:center;\">1034.256 ms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I expect the metrics to get worse as the threshold increases. All metrics are consistent with this worsening except entropy and Calinski-Harabasz\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import seaborn as sns\n",
    "import numpy as xnp\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "#from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#library for euclidean distance calculation\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "#library for Entropy calculation\n",
    "from scipy.stats import entropy\n",
    "\n",
    "#library for Calinski-Harabasz score calculation\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "\n",
    "#library for davies_bouldin score calculation\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "#library for table style\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from gap_statistic import OptimalK\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "#python font increase library\n",
    "from termcolor import colored\n",
    "\n",
    "#to save output\n",
    "from nbconvert import HTMLExporter\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "\n",
    "\n",
    "#function for dunn_index score calculation\n",
    "def dunn_index(X, labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    min_intercluster_distance = np.inf\n",
    "    max_intracluster_diameter = -np.inf\n",
    "\n",
    "    for i in range(len(unique_labels)):\n",
    "        for j in range(i + 1, len(unique_labels)):\n",
    "            cluster_i_points = X[labels == unique_labels[i]]\n",
    "            cluster_j_points = X[labels == unique_labels[j]]\n",
    "            \n",
    "            # Calculate the minimum distance between clusters\n",
    "            intercluster_distance = np.min(pairwise_distances(cluster_i_points, cluster_j_points))\n",
    "            min_intercluster_distance = min(min_intercluster_distance, intercluster_distance)\n",
    "\n",
    "        # Calculate the maximum intra-cluster diameter\n",
    "        intracluster_diameter = np.max(pairwise_distances(X[labels == unique_labels[i]]))\n",
    "        max_intracluster_diameter = max(max_intracluster_diameter, intracluster_diameter)\n",
    "\n",
    "        if max_intracluster_diameter == 0:\n",
    "            return 0  # Return zero or any other appropriate value\n",
    "        else:\n",
    "            return min_intercluster_distance / max_intracluster_diameter\n",
    "\n",
    "#set plot style with default seaborn style\n",
    "sns.set()\n",
    "\n",
    "silhouette_scores = []  \n",
    "entropy_scores = []\n",
    "calinski_harabasz_scores = []\n",
    "davies_bouldin_scores = []\n",
    "dunn_index_scores = [] \n",
    "gap_scores = []\n",
    "\n",
    "tempo_di_calcolo_silhouette = 0\n",
    "tempo_di_calcolo_entropy = 0\n",
    "tempo_di_calcolo_calinski_harabasz = 0\n",
    "tempo_di_calcolo_davies_bouldin = 0\n",
    "tempo_di_calcolo_dunn_index = 0\n",
    "tempo_di_calcolo_gap = 0\n",
    "\n",
    "\n",
    "#Creation of the DataFrame\n",
    "#df = pd.read_csv('toy_dataset_grouped.csv')\n",
    "#df = pd.read_csv('Takashi2019_diabetes_type1_dataset_preprocessed.csv')\n",
    "#df = pd.read_csv('journal.pone.0175818_S1Dataset_Spain_cardiac_arrest_EDITED.csv') #funziona male\n",
    "#df = pd.read_csv('journal.pone.0158570_S2File_depression_heart_failure.csv') #funziona male\n",
    "#df = pd.read_csv('journal.pone.0148699_S1_Text_Sepsis_SIRS_EDITED.csv') #funziona bene\n",
    "df = pd.read_csv('neuroblastoma.csv') #questo da problemi\n",
    "\n",
    "# Create a list with row indices\n",
    "row_indices = list(range(len(df)))\n",
    "\n",
    "# Shuffle index list randomly\n",
    "new_order = random.sample(row_indices, len(row_indices))\n",
    "\n",
    "# Reorder the DataFrame with the new row order\n",
    "df = df.iloc[new_order]\n",
    "\n",
    "# Normalize each column\n",
    "df = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "#calculate the maximum possible Euclidean distance\n",
    "arr = np.zeros((2, df.shape[1]))\n",
    "arr[1:] = 1\n",
    "max_euclidean_distances= pdist(arr, metric='euclidean')\n",
    "\n",
    "#print(max_euclidean_distances)\n",
    "\n",
    "#thresholds for clustering\n",
    "soglie = [0.2, 0.33] \n",
    "\n",
    "y=0\n",
    "for soglia in soglie:\n",
    "\n",
    "    soglia_percentuale = str(soglia * 100) + \"%\"\n",
    "    soglia = soglia * max_euclidean_distances\n",
    "\n",
    "    # Calcolo delle distanze euclidee\n",
    "    euclidean_distances= pdist(df.values, metric='euclidean')\n",
    "    distance_matrix = squareform(euclidean_distances)\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(40, 32))\n",
    "    sns.heatmap(distance_matrix, cmap='viridis', annot=True, fmt=\".3f\", xticklabels=row_indices, yticklabels=row_indices)\n",
    "    plt.title(\"Distanza Euclidea tra le righe della tabella\")\n",
    "    plt.xlabel(\"Righe\")\n",
    "    plt.ylabel(\"Righe\")\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    \n",
    "    cluster_labels_euclidean = []\n",
    "    \n",
    "    # Initialize an array to store cluster labels\n",
    "    cluster_labels = [-1] * len(df)\n",
    "    current_label = 0\n",
    "    \n",
    "    # Assign cluster labels based on the threshold\n",
    "    #parte da sistemare\n",
    "    for i in range(len(df)):\n",
    "        if cluster_labels[i] == -1:\n",
    "            cluster_labels[i] = current_label\n",
    "            for j in range(i+1, len(df)):\n",
    "                if distance_matrix[i, j] < soglia and cluster_labels[j] == -1:\n",
    "                    cluster_labels[j] = current_label\n",
    "            current_label += 1\n",
    "            if current_label == 2:\n",
    "                break\n",
    "\n",
    "    count_0 = cluster_labels.count(0)\n",
    "    count_1 = cluster_labels.count(1)\n",
    "\n",
    "    #create a mask that contain only the rows with a cluster_labels valued != -1\n",
    "    mask = np.array(cluster_labels) != -1\n",
    "    #apply the mask to generate the matrix with only the rows that i want\n",
    "    df_selected = df[mask]\n",
    "\n",
    "    mask = np.array(cluster_labels) != -1\n",
    "    cluster_labels_selected = np.array(cluster_labels)[mask]\n",
    "    \n",
    "    testo_grande = colored(\"result with threshold of \"+ str(soglia_percentuale), attrs=['bold', 'reverse'])\n",
    "    print(testo_grande+\"\\n\")\n",
    "    \n",
    "    # Print cluster labels\n",
    "    print(f\"Clusters with threshold {soglia_percentuale}: {cluster_labels}\")\n",
    "    print(f\"Clusters with Euclidean distance : {cluster_labels_selected}\")\n",
    "    \n",
    "    \n",
    "    # Calcolo del clustering con k-means\n",
    "    random_state = 45\n",
    "    kmeans = KMeans(n_clusters=2,random_state=random_state)\n",
    "    kmeans_clusters = kmeans.fit_predict(df_selected)\n",
    "    l= kmeans.labels_\n",
    "    \n",
    "    #count how many elements there are for each cluster\n",
    "    cluster_counts = np.bincount(l)\n",
    "    print(f\"Clusters with K-means : {kmeans_clusters}\")\n",
    "    \n",
    "    \n",
    "    # Inizializza una lista per tenere traccia dei tempi di calcolo\n",
    "    tempi_di_calcolo = np.empty((6, 7))\n",
    "\n",
    "    if len(l) > 2: \n",
    "    \n",
    "        # Silhouette calculation\n",
    "        start_time = time.time()\n",
    "        silhouette_avg = silhouette_score(df_selected, l)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "        end_time = time.time()\n",
    "        tempo_di_calcolo = end_time - start_time\n",
    "        tempo_di_calcolo_silhouette = tempo_di_calcolo_silhouette + tempo_di_calcolo\n",
    "        \n",
    "        # Entropy calculation (complementary Entropy)\n",
    "        start_time = time.time()\n",
    "        entropy_val = entropy(np.bincount(l) / len(l), base=2)\n",
    "        entropy_val = abs(1-entropy_val)\n",
    "        entropy_scores.append(entropy_val)\n",
    "        end_time = time.time()\n",
    "        tempo_di_calcolo = end_time - start_time\n",
    "        tempo_di_calcolo_entropy = tempo_di_calcolo_entropy + tempo_di_calcolo\n",
    "    \n",
    "        # Calinski-Harabasz index calculation\n",
    "        start_time = time.time()\n",
    "        calinski_harabasz_index = calinski_harabasz_score(df_selected, l)\n",
    "        calinski_harabasz_scores.append(calinski_harabasz_index)\n",
    "        end_time = time.time()\n",
    "        tempo_di_calcolo = end_time - start_time\n",
    "        tempo_di_calcolo_calinski_harabasz = tempo_di_calcolo_calinski_harabasz + tempo_di_calcolo\n",
    "    \n",
    "        # Davies-Bouldin calculation (reciprocal function)\n",
    "        start_time = time.time()\n",
    "        davies_bouldin_avg = davies_bouldin_score(df_selected, l)\n",
    "        davies_bouldin_avg = 1 / davies_bouldin_avg\n",
    "        davies_bouldin_scores.append(davies_bouldin_avg)\n",
    "        end_time = time.time()\n",
    "        tempo_di_calcolo = end_time - start_time\n",
    "        tempo_di_calcolo_davies_bouldin = tempo_di_calcolo_davies_bouldin + tempo_di_calcolo\n",
    "    \n",
    "        # Dunn index calculation\n",
    "        start_time = time.time()\n",
    "        dunn_score = dunn_index(df_selected, cluster_labels_selected)\n",
    "        dunn_index_scores.append(dunn_score)\n",
    "        end_time = time.time()\n",
    "        tempo_di_calcolo = end_time - start_time\n",
    "        tempo_di_calcolo_dunn_index = tempo_di_calcolo_dunn_index + tempo_di_calcolo\n",
    "    \n",
    "        # Gap Statistic calculation\n",
    "        start_time = time.time()\n",
    "        optimal_k = OptimalK(parallel_backend='joblib')\n",
    "        n_clusters = optimal_k(df_selected, cluster_array=np.arange(1, 3))\n",
    "        gap_df = optimal_k.gap_df\n",
    "        optimal_gap_statistic = gap_df.loc[gap_df.gap_value.idxmax(), 'gap_value']\n",
    "        gap_scores.append(optimal_gap_statistic)\n",
    "        end_time = time.time()\n",
    "        tempo_di_calcolo = end_time - start_time\n",
    "        tempo_di_calcolo_gap = tempo_di_calcolo_gap + tempo_di_calcolo\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Metrics calculated on the labels obtained from the Euclidean distance:\")\n",
    "        print(\"Silhouette Score:\", silhouette_scores[y])\n",
    "        print(\"Complementary Entropy Score:\", entropy_scores[y])\n",
    "        print(\"Calinski-Harabasz Score:\", calinski_harabasz_scores[y])\n",
    "        print(\"Reciprocal Davies-Bouldin Score:\", davies_bouldin_scores[y])\n",
    "        print(\"Dunn index Score:\", dunn_index_scores[y])\n",
    "        print(\"Gap Statistic Score:\", gap_scores[y])\n",
    "        print(\"\")\n",
    "    \n",
    "    # application of Adjusted Rand Index\n",
    "    ari = adjusted_rand_score(cluster_labels_selected, kmeans_clusters)\n",
    "    print(\"\\nTo compare the results obtained with the Euclidean distance and those obtained with k-means I use the range adjusted Rand index\")\n",
    "    print(\"range adjusted Rand index: [-1, 1]\")\n",
    "    print(f\"Threshold: {soglia_percentuale}, adjusted Rand index: {ari}\")\n",
    "\n",
    "   \n",
    "\n",
    "    #table with Euclidean distance clustering values\n",
    "    table_df = pd.DataFrame(columns=[\"cluster\", \"cluster elements\", \"%\"])\n",
    "    \n",
    "    dati_tabella = [\n",
    "        [\"1st cluster\", str(count_0) + \" patients out of \" + str(df.shape[0]) , count_0  / df.shape[0] * 100],\n",
    "        [\"2nd cluster\", str(count_1) + \" patients out of \" + str(df.shape[0]), count_1  / df.shape[0] * 100],\n",
    "        [\"no cluster\",str(df.shape[0]-(count_0+count_1))+ \" patients out of \" + str(df.shape[0]), (df.shape[0]-(count_0+count_1)) / df.shape[0] * 100],\n",
    "    ]\n",
    "    \n",
    "    for row_data in dati_tabella:\n",
    "        table_df.loc[len(table_df)] = row_data\n",
    "        \n",
    "    table_df.style \\\n",
    "      .format(precision=3, thousands=\".\", decimal=\",\").set_properties(**{'text-align': 'left'})\n",
    "    \n",
    "    html_table = table_df.to_html(index=False, classes=\"table table-striped\", border=0)\n",
    "    html_table = html_table.replace('<table', '<table style=\"width:100%;\" text-align:center;\"')\n",
    "    html_table = html_table.replace('<td', '<td style=\"text-align:center;\"').replace('<th', '<th style=\"text-align:center;\"')\n",
    "\n",
    "    print(\"\\n\")\n",
    "    html_table = \"<caption>Table with Euclidean distance clustering values:</caption>\" + html_table\n",
    "\n",
    "    \n",
    "    table_df.to_csv(\"/Users/andreaspagnolo/Desktop/uni/stage/result/result_real_data/euclidean_distance_result\" + \".csv\")\n",
    "    \n",
    "    #print table\n",
    "    display(HTML(html_table))\n",
    "\n",
    "    #print % of correct classification\n",
    "    var1 = round((( count_0+count_1 ) / df.shape[0]) * 100 ,3)\n",
    "    var2 = round(((df.shape[0]-(count_0+count_1))/df.shape[0])*100 ,3)\n",
    "    print(str(var1)  + \"% of the elements were correctly classified into the two clusters. The remaining \" + str(var2) + \"% of items were not classified\")\n",
    "\n",
    "\n",
    "    \n",
    "    #Table with K-means clustering values\n",
    "    table_df_2 = pd.DataFrame(columns=[\"cluster\", \"cluster elements\", \"%\"])\n",
    "    \n",
    "    dati_tabella2 = [\n",
    "        [\"1st cluster\", str(cluster_counts[0]) + \" patients out of \" + str(df.shape[0]) , cluster_counts[0]  / df.shape[0] * 100],\n",
    "        [\"2nd cluster\", str(cluster_counts[1]) + \" patients out of \" + str(df.shape[0]), cluster_counts[1]  / df.shape[0] * 100],\n",
    "        [\"no cluster\", str(df.shape[0] - (cluster_counts[0] + cluster_counts[1])) + \" patients out of \" + str(df.shape[0]), (df.shape[0] - (cluster_counts[0] + cluster_counts[1])) / df.shape[0] * 100],\n",
    "    ]\n",
    "\n",
    "    \n",
    "    for row_data in dati_tabella2:\n",
    "        table_df_2.loc[len(table_df_2)] = row_data\n",
    "        \n",
    "    table_df_2.style \\\n",
    "      .format(precision=3, thousands=\".\", decimal=\",\").set_properties(**{'text-align': 'left'})\n",
    "    \n",
    "    html_table2 = table_df_2.to_html(index=False, classes=\"table table-striped\", border=0)\n",
    "    html_table2 = html_table2.replace('<table', '<table style=\"width:100%;\" text-align:center;\"')\n",
    "    html_table2 = html_table2.replace('<td', '<td style=\"text-align:center;\"').replace('<th', '<th style=\"text-align:center;\"')\n",
    "\n",
    "    print(\"\\n\")\n",
    "    html_table2 = \"<caption>Table with K-means clustering values:</caption>\" + html_table2   \n",
    "\n",
    "    table_df_2.to_csv(\"/Users/andreaspagnolo/Desktop/uni/stage/result/result_real_data/kmeans_result\" + \".csv\")\n",
    "    \n",
    "    #print table\n",
    "    display(HTML(html_table2))\n",
    "\n",
    "    \n",
    "    tempo_di_calcolo_silhouette = tempo_di_calcolo_silhouette + tempo_di_calcolo_silhouette   \n",
    "    tempo_di_calcolo_entropy = tempo_di_calcolo_entropy + tempo_di_calcolo_entropy     \n",
    "    tempo_di_calcolo_calinski_harabasz = tempo_di_calcolo_calinski_harabasz + tempo_di_calcolo_calinski_harabasz\n",
    "    tempo_di_calcolo_davies_bouldin = tempo_di_calcolo_davies_bouldin + tempo_di_calcolo_davies_bouldin\n",
    "    tempo_di_calcolo_dunn_index = tempo_di_calcolo_dunn_index + tempo_di_calcolo_dunn_index\n",
    "    tempo_di_calcolo_gap = tempo_di_calcolo_gap + tempo_di_calcolo_gap \n",
    "\n",
    "     #save output in a file\n",
    "    with open(\"/Users/andreaspagnolo/Desktop/uni/stage/result/result_real_data/output.txt\", \"w\") as file:\n",
    "        file.write(\"result with threshold of \"+ str(soglia_percentuale) + \"\\n\")\n",
    "        file.write(f\"Clusters with threshold {soglia_percentuale}: {cluster_labels}\\n\")\n",
    "        file.write(f\"Clusters with Euclidean distance : {cluster_labels_selected}\\n\")\n",
    "        file.write(f\"Clusters with K-means : {kmeans_clusters}\\n\\n\")\n",
    "        file.write(\"Metrics calculated on the labels obtained from the Euclidean distance:\\n\")\n",
    "        file.write(f\"Silhouette Score: {silhouette_scores[y]}\\n\")\n",
    "        file.write(f\"Complementary Entropy Score: {entropy_scores[y]}\\n\")\n",
    "        file.write(f\"Calinski-Harabasz Score: {calinski_harabasz_scores[y]}\\n\")\n",
    "        file.write(f\"Reciprocal Davies-Bouldin Score: {davies_bouldin_scores[y]}\\n\")\n",
    "        file.write(f\"Dunn index Score: {dunn_index_scores[y]}\\n\")\n",
    "        file.write(f\"Gap Statistic Score: {gap_scores[y]}\\n\\n\")\n",
    "        file.write(\"To compare the results obtained with the Euclidean distance and those obtained with k-means I use the range adjusted Rand index\\n\")\n",
    "        file.write(\"range adjusted Rand index: [-1, 1]\\n\")\n",
    "        file.write(f\"Threshold: {soglia_percentuale}, adjusted Rand index: {ari}\\n\")\n",
    "\n",
    "    y+=1\n",
    "\n",
    "silhouette_trend = []      \n",
    "entropy_trend = []\n",
    "calinski_harabasz_trend = []\n",
    "davies_bouldin_trend = []\n",
    "dunn_index_trend = [] \n",
    "gap_trend = []\n",
    "\n",
    "silhouette_range = 2\n",
    "entropy_range = 1\n",
    "davies_bouldin_range = abs(davies_bouldin_scores[0]-davies_bouldin_scores[-1])\n",
    "dunn_index_range = abs(dunn_index_scores[0]-dunn_index_scores[-1])\n",
    "calinski_harabasz_range = abs(calinski_harabasz_scores[0]-calinski_harabasz_scores[-1])\n",
    "gap_range = abs(gap_scores[0]-gap_scores[-1])\n",
    "\n",
    "trend = [] \n",
    "def calculate_trend(current_value, previous_value, metric_scores,metric_range, threshold=10):\n",
    "    cambiamento_minimo = metric_range * 0.01\n",
    "    \n",
    "    final_change = metric_scores[0]-metric_scores[-1]\n",
    "    change = ((current_value - previous_value)/previous_value) * 100\n",
    "    if abs(final_change) < cambiamento_minimo:\n",
    "        return \"Wrong\"\n",
    "    elif change > threshold:\n",
    "        return \"Wrong\" #incresing\n",
    "    else:\n",
    "        return \"Correct\" #decresing\n",
    "\n",
    "i=0\n",
    "irregular=0\n",
    "for i in range(1, len(silhouette_scores)):\n",
    "    trend_per_iteration = calculate_trend(silhouette_scores[i], silhouette_scores[i-1], silhouette_scores,silhouette_range)\n",
    "    silhouette_trend.append(trend_per_iteration)\n",
    "    for i in range (len(silhouette_trend)):\n",
    "        if i > 0 and silhouette_trend[i] != silhouette_trend[i-1]:\n",
    "            irregular = irregular + 1\n",
    "if irregular >= 1:\n",
    "    trend.append(\"Wrong\")\n",
    "else:\n",
    "    trend.append(silhouette_trend[-1])\n",
    "\n",
    "i=0\n",
    "irregular=0\n",
    "for i in range(1, len(entropy_scores)):\n",
    "    trend_per_iteration = calculate_trend(entropy_scores[i], entropy_scores[i-1], entropy_scores,entropy_range)\n",
    "    entropy_trend.append(trend_per_iteration)\n",
    "    for i in range (len(entropy_trend)):\n",
    "        if i > 0 and entropy_trend[i] != entropy_trend[i-1]:\n",
    "            irregular = irregular + 1\n",
    "if irregular >= 1:\n",
    "    trend.append(\"Wrong\")\n",
    "else:\n",
    "    trend.append(entropy_trend[-1])\n",
    "\n",
    "i=0\n",
    "irregular=0\n",
    "for i in range(1, len(davies_bouldin_scores)):\n",
    "    trend_per_iteration = calculate_trend(davies_bouldin_scores[i], davies_bouldin_scores[i-1], davies_bouldin_scores,davies_bouldin_range)\n",
    "    davies_bouldin_trend.append(trend_per_iteration)\n",
    "    for i in range (len(davies_bouldin_trend)):\n",
    "        if i > 0 and davies_bouldin_trend[i] != davies_bouldin_trend[i-1]:\n",
    "            irregular = irregular + 1\n",
    "if irregular >= 1:\n",
    "    trend.append(\"Wrong\")\n",
    "else:\n",
    "    trend.append(davies_bouldin_trend[-1])\n",
    "\n",
    "i=0\n",
    "irregular=0\n",
    "for i in range(1, len(dunn_index_scores)):\n",
    "    trend_per_iteration = calculate_trend(dunn_index_scores[i], dunn_index_scores[i-1], dunn_index_scores,dunn_index_range)\n",
    "    dunn_index_trend.append(trend_per_iteration)\n",
    "    for i in range (len(dunn_index_trend)):\n",
    "        if i > 0 and dunn_index_trend[i] != dunn_index_trend[i-1]:\n",
    "            irregular = irregular + 1\n",
    "if irregular >= 1:\n",
    "    trend.append(\"Wrong\")\n",
    "else:\n",
    "    trend.append(dunn_index_trend[-1])\n",
    "\n",
    "i=0\n",
    "irregular=0\n",
    "for i in range(1, len(calinski_harabasz_scores)):\n",
    "    trend_per_iteration = calculate_trend(calinski_harabasz_scores[i], calinski_harabasz_scores[i-1], calinski_harabasz_scores,calinski_harabasz_range)\n",
    "    calinski_harabasz_trend.append(trend_per_iteration)\n",
    "    for i in range (len(calinski_harabasz_trend)):\n",
    "        if i > 0 and calinski_harabasz_trend[i] != calinski_harabasz_trend[i-1]:\n",
    "            irregular = irregular + 1\n",
    "if irregular >= 1:\n",
    "    trend.append(\"Wrong\")\n",
    "else:\n",
    "    trend.append(calinski_harabasz_trend[-1])\n",
    "\n",
    "i=0\n",
    "irregular=0\n",
    "for i in range(1, len(gap_scores)):\n",
    "    trend_per_iteration = calculate_trend(gap_scores[i], gap_scores[i-1], gap_scores,gap_range)\n",
    "    gap_trend.append(trend_per_iteration)\n",
    "    for i in range (len(gap_trend)):\n",
    "        if i > 0 and gap_trend[i] != gap_trend[i-1]:\n",
    "            irregular = irregular + 1\n",
    "if irregular >= 1:\n",
    "    trend.append(\"Wrong\")\n",
    "else:\n",
    "    trend.append(gap_trend[-1])\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "table_df3 = pd.DataFrame(columns=[\"metric\", \"result\", \"time\"])\n",
    "    \n",
    "dati_tabella3 = [\n",
    "    [\"Silhouette\", trend[0], str(round ((tempo_di_calcolo_silhouette / len(soglie)) *1000,3)) + \" ms\"],\n",
    "    [\"Complementary Entropy\", trend[1], str(round ((tempo_di_calcolo_entropy / len(soglie)) *1000,3)) + \" ms\"],\n",
    "    [\"Reciprocal Davies-Bouldin\", trend[2], str(round ((tempo_di_calcolo_davies_bouldin/ len(soglie))*1000,3)) + \" ms\"],\n",
    "    [\"Dunn index\", trend[3], str(round ((tempo_di_calcolo_dunn_index / len(soglie))*1000,3)) + \" ms\"],\n",
    "    [\"Calinski-Harabasz\", trend[4], str(round ((tempo_di_calcolo_calinski_harabasz / len(soglie))*1000,3)) + \" ms\"],\n",
    "    [\"Gap Statistic\", trend[5], str(round ((tempo_di_calcolo_gap / len(soglie))*1000,3)) + \" ms\"]\n",
    "]\n",
    "\n",
    "for row_data in dati_tabella3:\n",
    "    table_df3.loc[len(table_df3)] = row_data\n",
    "\n",
    "table_df3.style \\\n",
    ".format(precision=3, thousands=\".\", decimal=\",\").set_properties(**{'text-align': 'left'})\n",
    "\n",
    "html_table3 = table_df3.to_html(index=False, classes=\"table table-striped\", border=0)\n",
    "html_table3 = html_table3.replace('<table', '<table style=\"width:100%;\" text-align:center;\"')\n",
    "html_table3 = html_table3.replace('<td', '<td style=\"text-align:center;\"').replace('<th', '<th style=\"text-align:center;\"')\n",
    "\n",
    "print(\"\\n\")\n",
    "html_table3 = \"<caption>Table with metric result:</caption>\" + html_table3  \n",
    "\n",
    "table_df3.to_csv(\"/Users/andreaspagnolo/Desktop/uni/stage/result/result_real_data/metric_result\" + \".csv\")\n",
    "\n",
    "#print table\n",
    "display(HTML(html_table3))\n",
    "print(\"I expect the metrics to get worse as the threshold increases. All metrics are consistent with this worsening except entropy and Calinski-Harabasz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
